import os
import io
import time
import json
import random
import datetime
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
import google.generativeai as genai
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import subprocess 
import logging

# ==========================================
# â˜…è¿½åŠ : GitHubè‡ªå‹•åŒæœŸæ©Ÿèƒ½
# ==========================================
def auto_git_push(commit_message="Auto update trade memory"):
    """
    å­¦ç¿’çµæœ(CSV)ã‚’è‡ªå‹•ã§GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹
    """
    try:
        print("\nâ˜ï¸ GitHubã¸åŒæœŸä¸­...")
        subprocess.run(["git", "add", "ai_trade_memory_risk_managed.csv"], check=True)
        try:
            subprocess.run(["git", "commit", "-m", commit_message], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        except subprocess.CalledProcessError:
            print("   (å¤‰æ›´ãŒãªã„ãŸã‚ã‚³ãƒŸãƒƒãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ)")
            
        print("   æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        try:
            subprocess.run(["git", "pull", "--rebase"], check=True)
        except subprocess.CalledProcessError:
            print("âš ï¸ Pullä¸­ã«ç«¶åˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§è§£æ±ºã—ã¦ãã ã•ã„ã€‚")
            return

        subprocess.run(["git", "push"], check=True)
        print("âœ… åŒæœŸå®Œäº†ï¼ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚")
        
    except Exception as e:
        print(f"âš ï¸ GitHubåŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

try:
    from dotenv import load_dotenv
    load_dotenv(override=True)
except ImportError:
    pass

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
GOOGLE_API_KEY = os.getenv("TRAINING_API_KEY", "").strip()
if not GOOGLE_API_KEY:
    print("ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY (TRAINING_API_KEY) ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

genai.configure(api_key=GOOGLE_API_KEY)
MODEL_NAME = 'models/gemini-2.0-flash' 
LOG_FILE = "ai_trade_memory_risk_managed.csv" 

TRAINING_ROUNDS = 500 
TIMEFRAME = "1d" 
CBR_NEIGHBORS_COUNT = 15 
MIN_VOLATILITY = 1.0 

# ç·´ç¿’ç”¨éŠ˜æŸ„ãƒªã‚¹ãƒˆ
TRAINING_LIST = [
    "8035.T", "6146.T", "6857.T", "6723.T", "7735.T", "6526.T", "6758.T", "6861.T", "6501.T",
    "6594.T", "7751.T", "6702.T", "6752.T", "6981.T", "6954.T", "6920.T",
    "7203.T", "7267.T", "7269.T", "7270.T", "7011.T", "6301.T", "6367.T", "6098.T",
    "8306.T", "8316.T", "8411.T", "8766.T", "8591.T", "8604.T",
    "8058.T", "8031.T", "8001.T", "8002.T", "8053.T",
    "9432.T", "9433.T", "9984.T", "4661.T", "9613.T", "2413.T", "4751.T", "4385.T",
    "9983.T", "3382.T", "8267.T", "2802.T", "2914.T", "4911.T",
    "9101.T", "9104.T", "9107.T", "9020.T", "9021.T", "9201.T",
    "5401.T", "1605.T", "5713.T", "4063.T", "4901.T"
]
plt.rcParams['font.family'] = 'sans-serif' 

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾— & ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«è¨ˆç®—
# ==========================================
def download_data_safe(ticker, period="2y", interval="1d", retries=5):
    wait = 2
    for attempt in range(retries):
        try:
            logging.getLogger('yfinance').setLevel(logging.CRITICAL)
            df = yf.download(ticker, period=period, interval=interval, progress=False, auto_adjust=True)
            if df.empty: return None
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
            if len(df) < 50: return None
            return df
        except Exception as e:
            if attempt < retries - 1:
                time.sleep(wait)
                wait *= 2
            else:
                return None
    return None

def calculate_technical_indicators(df):
    df = df.copy()
    df['SMA25'] = df['Close'].rolling(25).mean()
    exp12 = df['Close'].ewm(span=12, adjust=False).mean()
    exp26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp12 - exp26
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()

    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR'] = tr.rolling(14).mean()
    df['VolumeMA5'] = df['Volume'].rolling(5).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(9).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(9).mean()
    rs = gain / loss
    df['RSI9'] = 100 - (100 / (1 + rs))
    return df.dropna()

def calculate_metrics_enhanced(df, idx):
    curr = df.iloc[idx]
    price = float(curr['Close'])
    sma25 = float(curr['SMA25'])
    sma25_dev = ((price / sma25) - 1) * 100
    prev_sma25 = float(df['SMA25'].iloc[idx-5])
    slope = (sma25 - prev_sma25) / 5
    trend_momentum = (slope / price) * 1000
    macd = float(curr['MACD'])
    signal = float(curr['Signal'])
    macd_power = ((macd - signal) / price) * 10000
    atr = float(curr['ATR'])
    entry_volatility = (atr / price) * 100
    std = df['Close'].iloc[idx-19:idx+1].std()
    bb_width = (4 * std) / df['Close'].iloc[idx-19:idx+1].mean() * 100
    vol_ma5 = float(curr['VolumeMA5'])
    volume_ratio = float(curr['Volume']) / vol_ma5 if vol_ma5 > 0 else 1.0
    
    return {
        'sma25_dev': sma25_dev,
        'trend_momentum': trend_momentum,
        'macd_power': macd_power,
        'entry_volatility': entry_volatility, 
        'price': price,
        'atr_value': atr,
        'bb_width': bb_width,
        'volume_ratio': volume_ratio,
        'rsi_9': float(curr['RSI9'])
    }

# ==========================================
# 2. CBRãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ  (è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ä»˜ã)
# ==========================================
class CaseBasedMemory:
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.scaler = StandardScaler()
        self.knn = None
        self.df = pd.DataFrame()
        self.feature_cols = ['sma25_dev', 'trend_momentum', 'macd_power', 'entry_volatility', 'rsi_9']
        self.load_and_train()

    def load_and_train(self):
        if not os.path.exists(self.csv_path): return
        
        try:
            self.df = pd.read_csv(self.csv_path)
        except Exception as e:
            print(f"âš ï¸ CSVèª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ”„ è‡ªå‹•ä¿®å¾©ãƒ¢ãƒ¼ãƒ‰ã§å†è©¦è¡Œ...")
            try:
                self.df = pd.read_csv(self.csv_path, on_bad_lines='skip')
                self.df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')
                print(f"âœ… ä¿®å¾©å®Œäº† (æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(self.df)}ä»¶)")
            except Exception as e2:
                print(f"âŒ ä¿®å¾©å¤±æ•—: {e2}")
                return

        try:
            rename_map = {
                'date': 'Date', 'ticker': 'Ticker', 'action': 'Action', 
                'reason': 'Reason', 'timeframe': 'Timeframe', 
                'result': 'result', 'profit_loss': 'profit_loss',
                'confidence': 'Confidence'
            }
            self.df.columns = [rename_map.get(col.lower(), col) for col in self.df.columns]
            
            valid_df = self.df[self.df['result'].isin(['WIN', 'LOSS'])].copy()
            
            if len(valid_df) < 5: return

            for col in self.feature_cols:
                 if col not in valid_df.columns: valid_df[col] = 0.0
            
            features = valid_df[self.feature_cols].fillna(0)
            self.features_normalized = self.scaler.fit_transform(features)
            
            self.valid_df_for_knn = valid_df 
            
            global CBR_NEIGHBORS_COUNT
            self.knn = NearestNeighbors(n_neighbors=min(CBR_NEIGHBORS_COUNT, len(valid_df)), metric='euclidean')
            self.knn.fit(self.features_normalized)
            print(f"Memory Loaded: {len(valid_df)} valid records.")
        except Exception as e:
            print(f"Memory Init Error: {e}")

    def search_similar_cases(self, current_metrics):
        if self.knn is None: return "ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"

        metrics_vec = []
        for col in self.feature_cols:
            metrics_vec.append(current_metrics.get(col, 0))
            
        input_df = pd.DataFrame([metrics_vec], columns=self.feature_cols)
        scaled_vec = self.scaler.transform(input_df)
        distances, indices = self.knn.kneighbors(scaled_vec)
        
        text = f"ã€éå»ã®é¡ä¼¼å±€é¢ ({len(indices[0])}ä»¶)ã€‘\n"
        win_c = 0
        loss_c = 0
        
        for idx in indices[0]:
            row = self.valid_df_for_knn.iloc[idx]
            res = str(row.get('result', ''))
            if res == 'WIN': win_c += 1
            if res == 'LOSS': loss_c += 1
            icon = "â­•" if res == 'WIN' else "âŒ"
            text += f"- {row.get('Date')} {row.get('Ticker')}: {icon} (MOM:{row.get('trend_momentum',0):.1f})\n"
            
        text += f"-> é¡ä¼¼ãƒ‡ãƒ¼ã‚¿å‚¾å‘: å‹ã¡{win_c} / è² ã‘{loss_c}\n"
        return text

    def save_experience(self, data_dict):
        csv_columns = [
            "Date", "Ticker", "Timeframe", "Action", "result", "Reason", 
            "Confidence", "stop_loss_price", "stop_loss_reason", "Price", 
            "sma25_dev", "trend_momentum", "macd_power", "entry_volatility","profit_loss"
        ]
        
        new_df = pd.DataFrame([data_dict])
        for col in csv_columns:
            if col not in new_df.columns: new_df[col] = None
        new_df = new_df[csv_columns]

        max_retries = 5
        for i in range(max_retries):
            try:
                if not os.path.exists(self.csv_path):
                    new_df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')
                else:
                    new_df.to_csv(self.csv_path, mode='a', header=False, index=False, encoding='utf-8-sig')
                
                self.load_and_train() 
                return
            except PermissionError:
                time.sleep(2)
            except Exception as e:
                print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                break

# ==========================================
# 3. AIã‚¹ãƒ‘ãƒ¼ãƒªãƒ³ã‚° (è³‡ç”£é˜²è¡›ãƒ»ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ç‰ˆ)
# ==========================================
def create_chart_image(df, ticker_name):
    data = df.tail(75).copy() 
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)
    ax1.plot(data.index, data['Close'], label='Close', color='black', linewidth=1.2)
    ax1.plot(data.index, data['SMA25'], label='SMA25', color='orange', alpha=0.8, linestyle='--')
    ax1.set_title(f"{ticker_name} Trend Chart")
    ax1.legend(loc='upper left'); ax1.grid(True, alpha=0.3)
    ax2.plot(data.index, data['MACD'], label='MACD', color='red', linewidth=1.0)
    ax2.bar(data.index, data['MACD']-data['Signal'], color='gray', alpha=0.3)
    ax2.grid(True, alpha=0.3)
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=80, bbox_inches='tight'); plt.close(fig); buf.seek(0)
    return buf.getvalue()

def ai_decision_maker(model, chart_bytes, metrics, similar_cases_text, ticker):
    # --- ğŸ›¡ï¸ é‰„ã®æŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
    if metrics['trend_momentum'] < 0:
        return {"action": "HOLD", "confidence": 0, "reason": "ã€é‰„ã®æŸã€‘ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ (Momentum < 0)", "stop_loss_price": 0}
    if metrics['sma25_dev'] < 0:
        return {"action": "HOLD", "confidence": 0, "reason": "ã€é‰„ã®æŸã€‘SMA25å‰²ã‚Œ (æˆ»ã‚Šå¾…ã¡)", "stop_loss_price": 0}
    if metrics['entry_volatility'] > 2.5:
        return {"action": "HOLD", "confidence": 0, "reason": f"ã€é‰„ã®æŸã€‘ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£éå¤§ ({metrics['entry_volatility']:.2f}%)", "stop_loss_price": 0}

    prompt = f"""
### TASK
ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿è‡³ä¸Šä¸»ç¾©ã®AIãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼ã§ã™ã€‚
ã€Œæ„Ÿæƒ…ã€ã‚„ã€ŒæœŸå¾…ã€ã‚’æ’é™¤ã—ã€ä»¥ä¸‹ã®**çµ±è¨ˆçš„å‹ç‡ãŒé«˜ã„æ¡ä»¶**ã«åˆè‡´ã™ã‚‹å ´åˆã®ã¿ BUY ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

### RULES (çµ±è¨ˆçš„å„ªä½æ€§ã«åŸºã¥ãé‰„ã®æŸ)

**1. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ç¦æ­¢ (å³æ™‚HOLDå¯¾è±¡):**
   ä»¥ä¸‹ã®ã„ãšã‚Œã‹1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã¯ã€çµ¶å¯¾ã«BUYã—ã¦ã¯ãªã‚‰ãªã„ã€‚
   - **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ >= 2.6%**: (å‹ç‡34%ä»¥ä¸‹) ç›¸å ´ãŒè’ã‚Œã¦ãŠã‚Šå±é™ºã€‚
   - **SMA25ä¹–é›¢ç‡ <= 0.5%**: (å‹ç‡32%ä»¥ä¸‹) ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå‡ºã¦ã„ãªã„ã€ã¾ãŸã¯é€†å¼µã‚Šã€‚SMA25ã¯å››æ¨äº”å…¥ã§ã¯ãªã
   - **MACDãƒ‘ãƒ¯ãƒ¼ <= 0**: (å‹ç‡ä½) ä¸‹è½åœ§åŠ›ãŒæ®‹ã£ã¦ã„ã‚‹ã€‚

**2. BUY (æ–°è¦è²·ã„) ã®æ¡ä»¶:**
   *å‰æ: ä¸Šè¨˜ã®ç¦æ­¢æ¡ä»¶ã‚’å…¨ã¦ã‚¯ãƒªã‚¢ã—ã¦ã„ã‚‹ã“ã¨ã€‚*
   
   - **[ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³]:**
     - SMA25ä¹–é›¢ç‡ãŒ **+0.5% ã€œ +4.7%** ã®ç¯„å›²ã«ã‚ã‚‹ã€‚
     - MACDãƒ‘ãƒ¯ãƒ¼ãŒãƒ—ãƒ©ã‚¹ã§æ¨ç§»ã—ã¦ã„ã‚‹ã€‚
     - RSIãŒ 40ã€œ65 ã®ç¯„å›²ï¼ˆéç†±æ„ŸãŒãªã„ï¼‰ã€‚

### SCORING (è‡ªä¿¡åº¦ã®æ¡ç‚¹ - å³æ ¼åŒ–)**
   ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœã€**è‡ªä¿¡éå‰°(85ç‚¹ä»¥ä¸Š)ã¯è² ã‘ãƒ•ãƒ©ã‚°**ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹ã€‚
   - **80-85 (æ¨å¥¨):** [ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³] ã«å®Œå…¨ã«åˆè‡´ã—ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%æœªæº€ã®å ´åˆã€‚
   - **60-79 (æ…é‡):** æ¡ä»¶ã¯æº€ãŸã™ãŒã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%ã€œ2.6%ã®å ´åˆã€‚
   - **0 (è«–å¤–):** ç¦æ­¢æ¡ä»¶ã«1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã€‚è‡ªä¿¡åº¦ã‚’0ã«ã›ã‚ˆã€‚

### OUTPUT FORMAT (JSON ONLY)
{{
  "action": "BUY", "HOLD", "SELL",
  "confidence": 0-100,
  "stop_loss_price": 0.0,
  "stop_loss_reason": "ç†ç”±",
  "target_price": 0.0,
  "reason": "ç†ç”±(100æ–‡å­—ä»¥å†…)"
}}
"""
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    try:
        response = model.generate_content(
            [prompt, {'mime_type': 'image/png', 'data': chart_bytes}], 
            safety_settings=safety_settings
        )
        text = response.text.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match: text = match.group(0)
        return json.loads(text)
    except Exception as e:
        return {"action": "HOLD", "reason": f"Error: {e}", "confidence": 0, "stop_loss_price": 0}

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ (ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—å®Ÿè£…ç‰ˆ)
# ==========================================
def main():
    print(f"=== AIå¼·åŒ–åˆå®¿ï¼ˆãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—å®Ÿè£…ç‰ˆï¼‰ ===")
    
    memory_system = CaseBasedMemory(LOG_FILE) 
    try: model_instance = genai.GenerativeModel(MODEL_NAME)
    except Exception as e: 
        print(f"Model Init Error: {e}")
        return

    processed_data = {}
    print(f"Downloading data...")
    for t in TRAINING_LIST:
        df = download_data_safe(t, interval=TIMEFRAME)
        if df is None or len(df) < 150: continue
        df = calculate_technical_indicators(df)
        processed_data[t] = df

    if not processed_data:
        print("ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    win_count = 0
    loss_count = 0
    
    print(f"\nğŸ¥Š ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ ({TRAINING_ROUNDS}ãƒ©ã‚¦ãƒ³ãƒ‰)\n")
    
    for i in range(1, TRAINING_ROUNDS + 1):
        ticker = random.choice(list(processed_data.keys()))
        df = processed_data[ticker]
        if len(df) < 110: continue 
        target_idx = random.randint(100, len(df) - 10) 
        current_date_str = df.index[target_idx].strftime('%Y-%m-%d')
        metrics = calculate_metrics_enhanced(df, target_idx)
        
        cbr_text = memory_system.search_similar_cases(metrics)
        past_df = df.iloc[:target_idx+1]
        chart_bytes = create_chart_image(past_df, ticker)
        
        decision = ai_decision_maker(model_instance, chart_bytes, metrics, cbr_text, ticker)
        action = decision.get('action', 'HOLD')
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹å¼·åˆ¶HOLDã‚¹ã‚­ãƒƒãƒ—
        if action == "HOLD" and "é‰„ã®æŸ" in decision.get('reason', ''):
            continue

        conf = decision.get('confidence', 0)
        action_display = "BUY ğŸ”´" if action == "BUY" else "HOLD ğŸŸ¡"
        print(f"Round {i:03}: {ticker} ({current_date_str}) -> {action_display} (è‡ªä¿¡:{conf}%)")

        result = "DRAW"
        profit_loss = 0.0
        
        if action == "BUY":
            # === â˜…ã“ã“ã‹ã‚‰å®Ÿè£…: ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ— ãƒ­ã‚¸ãƒƒã‚¯ ===
            entry_price = float(metrics['price'])
            
            # åˆæœŸæåˆ‡ã‚Šãƒ©ã‚¤ãƒ³: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã®-3.0% (å›ºå®š)
            current_stop_loss = entry_price * 0.97
            max_price = entry_price # æœ€é«˜å€¤è¿½è·¡ç”¨

            future_prices = df['Close'].iloc[target_idx+1 : target_idx+6]
            future_lows = df['Low'].iloc[target_idx+1 : target_idx+6]
            future_highs = df['High'].iloc[target_idx+1 : target_idx+6]
            
            is_win = False
            is_loss = False
            
            if len(future_prices) > 0:
                for j in range(len(future_prices)):
                    p_low = future_lows.iloc[j]
                    p_high = future_highs.iloc[j]
                    p_close = future_prices.iloc[j]
                    
                    # 1. æåˆ‡ã‚Šãƒã‚§ãƒƒã‚¯: å®‰å€¤ãŒã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ã«è§¦ã‚ŒãŸã‚‰å³æ±ºæ¸ˆ
                    if p_low <= current_stop_loss:
                        is_loss = True # æåˆ‡ã‚Š
                        profit_loss = current_stop_loss - entry_price
                        # print(f"   [Day{j+1}] æåˆ‡ã‚Šç™ºå‹•: {current_stop_loss:.0f}å†† (å®‰å€¤:{p_low:.0f})")
                        break
                    
                    # 2. ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°: é«˜å€¤ã‚’æ›´æ–°ã—ãŸã‚‰æåˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã‚’å¼•ãä¸Šã’ã‚‹
                    if p_high > max_price:
                        max_price = p_high
                        # æ–°ã—ã„æåˆ‡ã‚Šãƒ©ã‚¤ãƒ³ = æœ€é«˜å€¤ã®97%
                        new_stop_loss = max_price * 0.97
                        
                        # æåˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã¯ã€Œä¸Šã’ã‚‹ã€ã“ã¨ã—ã‹ã—ãªã„ï¼ˆä¸‹ã’ãªã„ï¼‰
                        if new_stop_loss > current_stop_loss:
                            current_stop_loss = new_stop_loss
                            # print(f"   [Day{j+1}] StopLossåˆ‡ä¸Š: {current_stop_loss:.0f}å†† (é«˜å€¤:{p_high:.0f})")

                # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã®åˆ¤å®š
                if is_loss:
                    result = "LOSS" if profit_loss < 0 else "WIN" # ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã§ãƒ—ãƒ©ã‚¹åŸŸã§æ±ºæ¸ˆã•ã‚ŒãŸå ´åˆã¯WIN
                else:
                    # 5æ—¥é–“æŒã¡ãã£ãŸå ´åˆã€æœ€çµ‚ä¾¡æ ¼ã§æ±ºæ¸ˆ
                    final_p = future_prices.iloc[-1]
                    profit_loss = final_p - entry_price
                    result = "WIN" if profit_loss > 0 else "LOSS"
            else:
                result = "Unknown"

            icon = "ğŸ†" if result == "WIN" else "ğŸ’€" if result == "LOSS" else "â–"
            print(f"   çµæœ: {icon} {result} (PL: {profit_loss:.1f}) > {decision.get('reason')}")
            
            if result == "WIN": win_count += 1
            if result == "LOSS": loss_count += 1
            
            save_data = {
                'Date': current_date_str, 'Ticker': ticker, 'Timeframe': TIMEFRAME, 
                'Action': action, 'result': result, 
                'Reason': decision.get('reason', 'None'),
                'Confidence': conf,
                'stop_loss_price': current_stop_loss, # æœ€çµ‚çš„ãªSLä¾¡æ ¼ã‚’è¨˜éŒ²
                'stop_loss_reason': "Trailing Stop", 
                'Price': metrics['price'],
                'sma25_dev': metrics['sma25_dev'], 
                'trend_momentum': metrics['trend_momentum'],
                'macd_power': metrics['macd_power'],
                'entry_volatility': metrics['entry_volatility'],
                'profit_loss': profit_loss
            }
            memory_system.save_experience(save_data)
        
        time.sleep(1)

    print(f"\n=== åˆå®¿çµ‚äº† ===")
    print(f"æˆ¦ç¸¾ (BUY): {win_count}å‹ {loss_count}æ•—")

if __name__ == "__main__":
    main()
    auto_git_push(commit_message="Training Camp Result Update (Trailing Stop)")