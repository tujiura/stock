import yfinance as yf
import pandas as pd
import google.generativeai as genai
import json
import time
import datetime
import urllib.parse
import feedparser
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import os
import io
import sys 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import socket
import requests.packages.urllib3.util.connection as urllib3_cn
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import logging

# ---------------------------------------------------------
# â˜…ç’°å¢ƒè¨­å®š
# ---------------------------------------------------------
sys.stdout.reconfigure(encoding='utf-8')

def allowed_gai_family():
    return socket.AF_INET
urllib3_cn.allowed_gai_family = allowed_gai_family

try:
    from dotenv import load_dotenv
    load_dotenv(override=True)
except ImportError:
    pass

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

webhook_url = os.getenv("DISCORD_WEBHOOK_URL")
genai.configure(api_key=GOOGLE_API_KEY)

# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
LOG_FILE = "ai_trade_memory_risk_managed.csv" # å­¦ç¿’ç”¨ãƒ¡ãƒ¢ãƒª
REAL_TRADE_LOG_FILE = "real_trade_record.csv" # å®Ÿæˆ¦ç”¨ãƒ­ã‚°
MODEL_NAME = 'models/gemini-2.0-flash' 

TIMEFRAME = "1d"
CBR_NEIGHBORS_COUNT = 15

# ç›£è¦–ãƒªã‚¹ãƒˆ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®å³é¸80éŠ˜æŸ„)
WATCH_LIST = [
    # --- ğŸ† ã‚¨ãƒ¼ã‚¹ç´š ---
    "6146.T", "8035.T", "9983.T", "7741.T", "6857.T", "7012.T", "6367.T", "7832.T",
    "1801.T", "9766.T", "2801.T", "4063.T", "4543.T", "4911.T", "4507.T",
    # --- ğŸ›¡ï¸ å®‰å®šãƒ»ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚·ãƒ– ---
    "9432.T", "9433.T", "9434.T", "4503.T", "4502.T", "2502.T", "2503.T", "2802.T",
    "4901.T", "1925.T", "1928.T", "1802.T", "1803.T", "1812.T", "9020.T", "9021.T",
    "9532.T", "9735.T", "9613.T",
    # --- ğŸ’° é‡‘èãƒ»éŠ€è¡Œ ---
    "8306.T", "8316.T", "8411.T", "8308.T", "8309.T", "8331.T", "8354.T", "8766.T",
    "8725.T", "8591.T", "8593.T", "8604.T", "8473.T", "8630.T", "8697.T",
    # --- ğŸ¢ å•†ç¤¾ãƒ»å¸å£² ---
    "8058.T", "8031.T", "8001.T", "8002.T", "8015.T", "2768.T", "8053.T", "7459.T",
    "8088.T", "9962.T", "3092.T", "3382.T",
    # --- ğŸ­ é‡åšé•·å¤§ãƒ»è‡ªå‹•è»Š ---
    "7011.T", "7013.T", "6301.T", "7203.T", "7267.T", "7269.T", "7270.T", "7201.T",
    "5401.T", "5411.T", "5713.T", "1605.T", "5020.T",
    # --- ğŸ“¦ ãã®ä»–ãƒ»æ©Ÿæ¢° ---
    "6501.T", "6503.T", "6305.T", "6326.T", "6383.T", "6471.T", "6473.T", "7751.T"
]

plt.rcParams['font.family'] = 'sans-serif'

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ç¾¤
# ==========================================
def download_data_safe(ticker, period="6mo", interval="1d", retries=3):
    wait = 2
    for attempt in range(retries):
        try:
            logging.getLogger('yfinance').setLevel(logging.CRITICAL)
            df = yf.download(ticker, period=period, interval=interval, progress=False, auto_adjust=True)
            if df.empty: return None
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
            if len(df) < 50: return None
            return df
        except:
            time.sleep(wait); wait *= 2
    return None

def get_macro_data():
    """ä¸»è¦æŒ‡æ•°ã‚’å–å¾—"""
    tickers = {"^N225": "æ—¥çµŒå¹³å‡", "JPY=X": "ãƒ‰ãƒ«å††", "^GSPC": "ç±³S&P500", "^TNX": "ç±³10å¹´å‚µ", "^VIX": "VIX"}
    report = "ã€ğŸŒ ãƒã‚¯ãƒ­ç’°å¢ƒã€‘\n"
    try:
        data = yf.download(list(tickers.keys()), period="5d", progress=False)
        if isinstance(data.columns, pd.MultiIndex): df_close = data['Close']
        else: df_close = data['Close'] if 'Close' in data else data

        for symbol, name in tickers.items():
            try:
                series = df_close[symbol].dropna()
                if len(series) < 2: continue
                current = float(series.iloc[-1])
                change = (current - float(series.iloc[-2])) / float(series.iloc[-2]) * 100
                icon = "â†—ï¸" if change > 0 else "â†˜ï¸"
                report += f"- {name}: {current:.2f} ({icon} {change:+.2f}%)\n"
            except: pass
    except: return "ã€ãƒã‚¯ãƒ­ç’°å¢ƒã€‘å–å¾—ã‚¨ãƒ©ãƒ¼"
    return report.strip()

def get_fundamentals(ticker):
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        if not info: return "ãƒ‡ãƒ¼ã‚¿ãªã—"
        name = info.get("longName", ticker)
        per = info.get("trailingPE", "-")
        pbr = info.get("priceToBook", "-")
        roe = info.get("returnOnEquity", "-")
        per_str = f"{per:.1f}å€" if isinstance(per, (int, float)) else "-"
        pbr_str = f"{pbr:.2f}å€" if isinstance(pbr, (int, float)) else "-"
        roe_str = f"{roe*100:.1f}%" if isinstance(roe, (int, float)) else "-"
        return f"- {name}\n- PER:{per_str}, PBR:{pbr_str}, ROE:{roe_str}"
    except: return "å–å¾—ã‚¨ãƒ©ãƒ¼"

def get_latest_news(ticker):
    try:
        q = urllib.parse.quote(f"{ticker} æ ªä¾¡ ãƒ‹ãƒ¥ãƒ¼ã‚¹")
        url = f"https://news.google.com/rss/search?q={q}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(url)
        if not feed.entries: return "ç‰¹ã«ãªã—"
        return "\n".join([f"ãƒ»{e.title}" for e in feed.entries[:2]])
    except: return "å–å¾—ã‚¨ãƒ©ãƒ¼"

def get_earnings_date(ticker):
    try:
        stock = yf.Ticker(ticker)
        calendar = stock.calendar
        if calendar and 'Earnings Date' in calendar:
            earnings_date = calendar['Earnings Date'][0]
            if isinstance(earnings_date, (datetime.date, datetime.datetime)):
                return earnings_date.strftime('%Y-%m-%d')
    except: pass
    return "-"

def get_weekly_trend(ticker):
    try:
        df = yf.download(ticker, period="1y", interval="1wk", progress=False, auto_adjust=True)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
        if len(df) < 26: return "ä¸æ˜"
        sma13 = df['Close'].rolling(13).mean().iloc[-1]
        sma26 = df['Close'].rolling(26).mean().iloc[-1]
        price = float(df['Close'].iloc[-1])
        if price > sma13 > sma26: return "ä¸Šæ˜‡ ğŸ“ˆ (å¼·)"
        elif price > sma13: return "ä¸Šæ˜‡ â†—ï¸ (çŸ­)"
        elif price < sma13 < sma26: return "ä¸‹é™ ğŸ“‰ (å¼±)"
        else: return "ãƒ¬ãƒ³ã‚¸ â¡ï¸"
    except: return "ä¸æ˜"

# ==========================================
# 2. æŒ‡æ¨™è¨ˆç®—
# ==========================================
def calculate_metrics_enhanced(df):
    if len(df) < 26: return None
    curr = df.iloc[-1]
    price = float(curr['Close'])
    
    sma25 = float(curr['SMA25'])
    sma25_dev = ((price / sma25) - 1) * 100
    
    prev_sma25 = float(df['SMA25'].iloc[-6])
    slope = (sma25 - prev_sma25) / 5
    trend_momentum = (slope / price) * 1000
    
    macd = float(curr['MACD'])
    signal = float(curr['Signal'])
    macd_power = ((macd - signal) / price) * 10000
    
    atr = float(curr['ATR'])
    entry_volatility = (atr / price) * 100
    
    # BBå¹…
    std = df['Close'].rolling(20).std().iloc[-1]
    bb_width = (4 * std) / df['Close'].rolling(20).mean().iloc[-1] * 100
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(9).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(9).mean()
    rs = gain / loss
    rsi_9 = 100 - (100 / (1 + rs)).iloc[-1]

    return {
        'sma25_dev': sma25_dev,
        'trend_momentum': trend_momentum,
        'macd_power': macd_power,
        'entry_volatility': entry_volatility,
        'price': price,
        'atr_value': atr,
        'bb_width': bb_width,
        'rsi_9': rsi_9
    }

# ==========================================
# 3. CBRãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ 
# ==========================================
class CaseBasedMemory:
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.scaler = StandardScaler()
        self.knn = None
        self.df = pd.DataFrame()
        self.feature_cols = ['sma25_dev', 'trend_momentum', 'macd_power', 'entry_volatility', 'rsi_9']
        
        self.csv_columns = [
            "Date", "Ticker", "Timeframe", "Action", "result", "Reason", 
            "Confidence", "stop_loss_price", "stop_loss_reason", "Price", 
            "sma25_dev", "trend_momentum", "macd_power", "entry_volatility", "rsi_9", 
            "profit_loss", "profit_rate" 
        ]
        self.load_and_train()

    def load_and_train(self):
        if not os.path.exists(self.csv_path): return
        
        try:
            self.df = pd.read_csv(self.csv_path)
            
            # --- ã‚¹ã‚­ãƒ¼ãƒè‡ªå‹•æ›´æ–° ---
            missing_cols = [col for col in self.csv_columns if col not in self.df.columns]
            if missing_cols:
                for col in missing_cols: self.df[col] = 0.0
                self.df = self.df[self.csv_columns]
                self.df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')

        except Exception as e:
            print(f"âš ï¸ CSVèª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
            try:
                self.df = pd.read_csv(self.csv_path, on_bad_lines='skip')
                missing_cols = [col for col in self.csv_columns if col not in self.df.columns]
                for col in missing_cols: self.df[col] = 0.0
                self.df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')
            except Exception: return

        try:
            rename_map = {'date': 'Date', 'ticker': 'Ticker', 'action': 'Action', 'result': 'result'}
            self.df.columns = [rename_map.get(col.lower(), col) for col in self.df.columns]
            
            valid_df = self.df[self.df['result'].isin(['WIN', 'LOSS'])].copy()
            if len(valid_df) < 5: return

            for col in self.feature_cols:
                 if col not in valid_df.columns: valid_df[col] = 0.0
            
            features = valid_df[self.feature_cols].fillna(0)
            self.features_normalized = self.scaler.fit_transform(features)
            
            self.valid_df_for_knn = valid_df 
            global CBR_NEIGHBORS_COUNT
            self.knn = NearestNeighbors(n_neighbors=min(CBR_NEIGHBORS_COUNT, len(valid_df)), metric='euclidean')
            self.knn.fit(self.features_normalized)
            print(f"Memory Loaded: {len(valid_df)} valid records.")
        except Exception as e:
            print(f"Memory Init Error: {e}")

    def search_similar_cases(self, current_metrics):
        if self.knn is None: return "ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"
        metrics_vec = [current_metrics.get(col, 0) for col in self.feature_cols]
        input_df = pd.DataFrame([metrics_vec], columns=self.feature_cols)
        scaled_vec = self.scaler.transform(input_df)
        distances, indices = self.knn.kneighbors(scaled_vec)
        
        text = f"ã€é¡ä¼¼éå»äº‹ä¾‹ã€‘\n"
        win_c = 0; loss_c = 0
        for idx in indices[0]:
            row = self.valid_df_for_knn.iloc[idx]
            res = str(row.get('result', ''))
            if res == 'WIN': win_c += 1
            if res == 'LOSS': loss_c += 1
            icon = "â­•" if res=='WIN' else "âŒ"
            text += f"- {row.get('Date')} {row.get('Ticker')}: {icon} (MOM:{row.get('trend_momentum',0):.1f})\n"
        text += f"-> å‚¾å‘: å‹ã¡{win_c} / è² ã‘{loss_c}\n"
        return text

# ==========================================
# 4. AIåˆ¤å®š
# ==========================================
def create_chart_image(df, name):
    data = df.tail(100).copy()
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)
    ax1.plot(data.index, data['Close'], color='black', label='Close')
    ax1.plot(data.index, data['SMA25'], color='orange', label='SMA25')
    ax1.set_title(f"{name} Analysis")
    ax1.legend(); ax1.grid(True, alpha=0.3)
    ax2.plot(data.index, data['MACD'], color='red')
    ax2.bar(data.index, data['MACD']-data['Signal'], color='gray', alpha=0.3)
    ax2.grid(True, alpha=0.3)
    buf = io.BytesIO(); plt.savefig(buf, format='png', dpi=80); plt.close(fig); buf.seek(0)
    return {"mime_type": "image/png", "data": buf.getvalue()}

def ai_decision_maker(model, chart_bytes, metrics, cbr_text, macro, news, fundamentals, weekly, ticker):
    # é‰„ã®æŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (æœ€é©åŒ–: 2.3%)
    if metrics['entry_volatility'] > 2.3:
        return {"action": "HOLD", "confidence": 0, "reason": f"ã€é‰„ã®æŸã€‘ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£éå¤§ ({metrics['entry_volatility']:.2f}%)"}
    if metrics['trend_momentum'] < 0:
        return {"action": "HOLD", "confidence": 0, "reason": "ã€é‰„ã®æŸã€‘ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ (Momentum < 0)"}
    if metrics['sma25_dev'] < 0:
        return {"action": "HOLD", "confidence": 0, "reason": "ã€é‰„ã®æŸã€‘SMA25å‰²ã‚Œ (æˆ»ã‚Šå¾…ã¡)"}

    prompt = f"""
### CONTEXT
å¯¾è±¡: {ticker}
ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã€‘
- ãƒˆãƒ¬ãƒ³ãƒ‰å‹¢ã„: {metrics['trend_momentum']:.2f} (ãƒ—ãƒ©ã‚¹å¿…é ˆ)
- SMA25ä¹–é›¢ç‡: {metrics['sma25_dev']:.2f}% (ãƒ—ãƒ©ã‚¹åœ)
- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {metrics['entry_volatility']:.2f}% (2.3%ä»¥ä¸‹æ¨å¥¨)
- RSI(9): {metrics['rsi_9']:.1f}
- ATR: {metrics['atr_value']:.1f}
- é€±è¶³ãƒˆãƒ¬ãƒ³ãƒ‰: {weekly}

{macro}

{fundamentals}

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘
{news}

{cbr_text}

### TASK
ã€Œè³‡ç”£é˜²è¡›å‹AIã€ã¨ã—ã¦ã€Œè²·ã„ (BUY)ã€ã‹ã€Œæ§˜å­è¦‹ (HOLD)ã€ã®ã¿åˆ¤å®šã›ã‚ˆã€‚ç©ºå£²ã‚Šä¸å¯ã€‚
å£²å´åˆ¤æ–­ã¯ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã«ä¸€ä»»ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã€Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®å„ªä½æ€§ã€ã®ã¿ã‚’å¯©æŸ»ã™ã‚‹ã€‚

### RULES (çµ±è¨ˆçš„å„ªä½æ€§ã«åŸºã¥ãé‰„ã®æŸ)

**1. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ç¦æ­¢ (å³æ™‚HOLDå¯¾è±¡):**
   ä»¥ä¸‹ã®ã„ãšã‚Œã‹1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã¯ã€çµ¶å¯¾ã«BUYã—ã¦ã¯ãªã‚‰ãªã„ã€‚
   - **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ >= 2.6%**: (å‹ç‡34%ä»¥ä¸‹) ç›¸å ´ãŒè’ã‚Œã¦ãŠã‚Šå±é™ºã€‚
   - **SMA25ä¹–é›¢ç‡ <= 0.5%**: (å‹ç‡32%ä»¥ä¸‹) ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå‡ºã¦ã„ãªã„ã€ã¾ãŸã¯é€†å¼µã‚Šã€‚SMA25ã¯å››æ¨äº”å…¥ã§ã¯ãªã
   - **MACDãƒ‘ãƒ¯ãƒ¼ <= 0**: (å‹ç‡ä½) ä¸‹è½åœ§åŠ›ãŒæ®‹ã£ã¦ã„ã‚‹ã€‚

**2. BUY (æ–°è¦è²·ã„) ã®æ¡ä»¶:**
   *å‰æ: ä¸Šè¨˜ã®ç¦æ­¢æ¡ä»¶ã‚’å…¨ã¦ã‚¯ãƒªã‚¢ã—ã¦ã„ã‚‹ã“ã¨ã€‚*
   
   - **[ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³]:**
     - SMA25ä¹–é›¢ç‡ãŒ **+0.5% ã€œ +4.7%** ã®ç¯„å›²ã«ã‚ã‚‹ã€‚
     - MACDãƒ‘ãƒ¯ãƒ¼ãŒãƒ—ãƒ©ã‚¹ã§æ¨ç§»ã—ã¦ã„ã‚‹ã€‚
     - RSIãŒ 40ã€œ65 ã®ç¯„å›²ï¼ˆéç†±æ„ŸãŒãªã„ï¼‰ã€‚

### SCORING (è‡ªä¿¡åº¦ã®æ¡ç‚¹ - å³æ ¼åŒ–)**
   ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœã€**è‡ªä¿¡éå‰°(85ç‚¹ä»¥ä¸Š)ã¯è² ã‘ãƒ•ãƒ©ã‚°**ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹ã€‚
   - **80-85 (æ¨å¥¨):** [ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³] ã«å®Œå…¨ã«åˆè‡´ã—ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%æœªæº€ã®å ´åˆã€‚
   - **60-79 (æ…é‡):** æ¡ä»¶ã¯æº€ãŸã™ãŒã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%ã€œ2.6%ã®å ´åˆã€‚
   - **0 (è«–å¤–):** ç¦æ­¢æ¡ä»¶ã«1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã€‚è‡ªä¿¡åº¦ã‚’0ã«ã›ã‚ˆã€‚

### OUTPUT FORMAT (JSON ONLY)
{{
  "action": "BUY", "HOLD", "SELL",
  "confidence": 0-100,
  "stop_loss_price": 0.0,
  "stop_loss_reason": "ç†ç”±",
  "target_price": 0.0,
  "reason": "ç†ç”±(100æ–‡å­—ä»¥å†…)"
}}
"""
    safety = {HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE}
    try:
        response = model.generate_content([prompt, chart_bytes], safety_settings=safety)
        text = response.text.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match: text = match.group(0)
        return json.loads(text)
    except Exception as e:
        return {"action": "HOLD", "reason": f"AI Error: {e}", "confidence": 0}

def send_discord_notify(message, filename=None):
    if not webhook_url: return
    try:
        now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
        payload = {"content": f"ğŸ“Š **AIå¸‚å ´ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ ({now_str})**\n{message[:1500]}"}
        
        files = {}
        if filename:
            files["file"] = (f"Report_{now_str.replace(':','-')}.txt", message.encode('utf-8'))
            
        requests.post(webhook_url, data=payload, files=files if filename else None)
        print("âœ… Discordé€šçŸ¥é€ä¿¡")
    except Exception as e:
        print(f"âš ï¸ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

# ==========================================
# 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==========================================
if __name__ == "__main__":
    today = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"=== AIå¸‚å ´ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  ({today}) ===")
    
    WATCH_LIST = sorted(list(set(WATCH_LIST)))
    try: model_instance = genai.GenerativeModel(MODEL_NAME)
    except Exception as e: print(f"Error: {e}"); exit()

    memory = CaseBasedMemory(LOG_FILE)
    macro = get_macro_data()
    print(macro)
    
    report_message = f"**ğŸ“Š AIå¸‚å ´ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ ({today})**\n\n{macro}\n"
    buy_list = []
    all_stock_prices = [] # å…¨éŠ˜æŸ„ä¾¡æ ¼ãƒªã‚¹ãƒˆ
    
    SAVE_TARGETS = [
        {"path": LOG_FILE, "name": "å­¦ç¿’ãƒ¡ãƒ¢ãƒª"},
        {"path": REAL_TRADE_LOG_FILE, "name": "å®Ÿæˆ¦ãƒ­ã‚°"}
    ]

    current_hour_jst = (datetime.datetime.utcnow() + datetime.timedelta(hours=9)).hour
    is_closing_time = (current_hour_jst >= 15)
    print(f"ğŸ•’ ç¾åœ¨ {current_hour_jst}æ™‚: {'è¨˜éŒ²ãƒ¢ãƒ¼ãƒ‰' if is_closing_time else 'ç›£è¦–ãƒ¢ãƒ¼ãƒ‰'}")

    for i, tic in enumerate(WATCH_LIST, 1):
        print(f"[{i}/{len(WATCH_LIST)}] {tic}... ", end="", flush=True)
        
        df = download_data_safe(tic, interval=TIMEFRAME)
        if df is None: print("Skip"); continue
        
        df['SMA25'] = df['Close'].rolling(25).mean()
        df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()
        df['Signal'] = df['MACD'].ewm(span=9).mean()
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        df['ATR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1).rolling(14).mean()
        
        df = df.dropna()
        metrics = calculate_metrics_enhanced(df)
        if metrics is None: print("Skip"); continue
        
        # --- æ ªä¾¡ãƒªã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ (ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ã«å®Ÿæ–½) ---
        current_price = metrics['price']
        try:
            prev_close = df['Close'].iloc[-2]
            change = current_price - prev_close
            change_pct = (change / prev_close) * 100
            price_str = f"â€¢ {tic}: {current_price:,.0f}å†† ({change:+.0f} / {change_pct:+.2f}%)"
        except:
            price_str = f"â€¢ {tic}: {current_price:,.0f}å††"
        all_stock_prices.append(price_str)

        # 3. é‰„ã®æŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (æœ€é©åŒ–: 2.3%)
        if metrics['trend_momentum'] < 0 or metrics['sma25_dev'] < 0 or metrics['entry_volatility'] > 2.3:
             print("â¹ï¸ Filtered"); continue

        # ä»˜åŠ æƒ…å ±å–å¾—
        earnings_date = get_earnings_date(tic)
        cbr_text = memory.search_similar_cases(metrics)
        chart = create_chart_image(df, tic)
        news = get_latest_news(tic)
        fund = get_fundamentals(tic)
        weekly = get_weekly_trend(tic)
        
        res = ai_decision_maker(model_instance, chart, metrics, cbr_text, macro, news, fund, weekly, tic)
        
        action = res.get('action', 'HOLD')
        conf = res.get('confidence', 0)
        
        # ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—è¨ˆç®— (BUYã®å ´åˆ)
        stop_loss_price = 0
        if action == "BUY":
            atr_stop = metrics['atr_value'] * 2.0
            stop_loss_price = metrics['price'] - atr_stop
        
        # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ (â˜…profit_rate 0.0ã§åˆæœŸåŒ–)
        item = {
            "Date": today, "Ticker": tic, "Timeframe": TIMEFRAME, 
            "Action": action, "result": "", "Reason": res.get('reason', 'None'), 
            "Confidence": conf, "stop_loss_price": stop_loss_price, "stop_loss_reason": "ATR_Trailing_Stop",
            "Price": metrics['price'], "sma25_dev": metrics['sma25_dev'], 
            "trend_momentum": metrics['trend_momentum'], "macd_power": metrics['macd_power'],
            "entry_volatility": metrics['entry_volatility'], "rsi_9": metrics['rsi_9'], 
            "profit_loss": 0,
            "profit_rate": 0.0 
        }
        
        # ä¿å­˜å‡¦ç† (15æ™‚ä»¥é™ã®ã¿)
        if is_closing_time:
            df_new = pd.DataFrame([item])
            # ã‚«ãƒ©ãƒ é †åºã‚’æƒãˆã‚‹
            for col in memory.csv_columns:
                if col not in df_new.columns: df_new[col] = None
            df_new = df_new[memory.csv_columns]
            
            for target in SAVE_TARGETS:
                try:
                    path = target["path"]
                    if os.path.exists(path):
                        df_new.to_csv(path, mode='a', header=False, index=False, encoding='utf-8-sig')
                    else:
                        df_new.to_csv(path, index=False, encoding='utf-8-sig')
                except: pass
            print(f"ğŸ“ {action} ({conf}%)")
        else:
            print(f"ğŸ‘€ {action} ({conf}%)")

        if action == "BUY" and conf >= 70:
            earnings_warning = f"\nâš ï¸ **æ±ºç®—æ³¨æ„**: {earnings_date}" if earnings_date != "-" else ""
            msg = (
                f"ğŸ”´ **BUY {tic}**: {metrics['price']:.0f}å††\n"
                f"ğŸ›¡ï¸ **æ¨å¥¨æåˆ‡ã‚Š**: **{stop_loss_price:.0f}å††** (ATR x2.0)\n"
                f"ğŸ’¡ **å‹åˆ©ã®æˆ¦è¡“**: \n"
                f"   ãƒ»å«ã¿ç›Š+3.0%ã¾ã§ã¯é€†æŒ‡å€¤ã‚’å‹•ã‹ã•ãªã„(å¿è€)\n"
                f"   ãƒ»+2.5%è¶…ã§å»ºå€¤ã‚¬ãƒ¼ãƒ‰ç™ºå‹•\n"
                f"   ãƒ»+3%è¶…ã§ATRè¿½å¾“é–‹å§‹ã€+5%è¶…ã§é¬¼åˆ©ç¢º\n"
                f"{earnings_warning}\n"
                f"> ç†ç”±: {res.get('reason')}"
            )
            buy_list.append(msg)
        time.sleep(2)

    if buy_list:
        report_message += "\n\nğŸš€ **æ–°è¦BUYæ¨å¥¨**\n" + "\n\n".join(buy_list)
    else:
        report_message += "\n\nğŸ’¤ æ¨å¥¨ãªã—"

    # å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’è¿½åŠ 
    if all_stock_prices:
        report_message += "\n\n" + "="*30 + "\nğŸ“‰ **ç›£è¦–éŠ˜æŸ„ æ ªä¾¡ä¸€è¦§**\n" + "="*30 + "\n"
        report_message += "\n".join(all_stock_prices)

    send_discord_notify(report_message, filename="FullReport")