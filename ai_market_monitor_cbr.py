import yfinance as yf
import pandas as pd
import google.generativeai as genai
import json
import time
import datetime
import urllib.parse
import feedparser
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import os
import io
import sys
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import socket
import requests.packages.urllib3.util.connection as urllib3_cn

# ---------------------------------------------------------
# â˜…ç’°å¢ƒè¨­å®š
# ---------------------------------------------------------
sys.stdout.reconfigure(encoding='utf-8')

def allowed_gai_family():
    return socket.AF_INET
urllib3_cn.allowed_gai_family = allowed_gai_family

try:
    from dotenv import load_dotenv
    load_dotenv(override=True)
except ImportError:
    pass

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    # exit() 

webhook_url = os.getenv("DISCORD_WEBHOOK_URL")
genai.configure(api_key=GOOGLE_API_KEY)

# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
LOG_FILE = "ai_trade_memory_risk_managed.csv" # å­¦ç¿’ç”¨ãƒ¡ãƒ¢ãƒªï¼ˆAIã®è„³ï¼‰
REAL_TRADE_LOG_FILE = "real_trade_record.csv" # å®Ÿæˆ¦ç”¨ãƒ­ã‚°ï¼ˆã‚ãªãŸã®è¨˜éŒ²ï¼‰

MODEL_NAME = 'models/gemini-2.0-flash' # æœ€æ–°ãƒ¢ãƒ‡ãƒ«æ¨å¥¨
TIMEFRAME = "1d"
CBR_NEIGHBORS_COUNT = 11

# ç›£è¦–ãƒªã‚¹ãƒˆ
WATCH_LIST = [
    "8035.T", "6146.T", "6920.T", "6857.T", "6723.T", "7735.T", "6526.T",
    "6758.T", "6861.T", "6501.T", "6503.T", "6981.T", "6954.T", "7741.T", 
    "6902.T", "6367.T", "6594.T", "7751.T",
    "7203.T", "7267.T", "7270.T", "7201.T", "7269.T",
    "8306.T", "8316.T", "8411.T", "8766.T", "8725.T", "8591.T", "8604.T",
    "8058.T", "8031.T", "8001.T", "8002.T", "8015.T", "2768.T",
    "7011.T", "7012.T", "7013.T", "6301.T", "5401.T", "9101.T", "9104.T", "9107.T",
    "9432.T", "9433.T", "9984.T", "9434.T", "4661.T", "6098.T",
    "7974.T", "9684.T", "9697.T", "7832.T",
    "9983.T", "3382.T", "8267.T", "9843.T", "3092.T", "4385.T", "7532.T",
    "4568.T", "4519.T", "4503.T", "4502.T", "4063.T", "4901.T", "4452.T", "2914.T",
    "8801.T", "8802.T", "1925.T", "1801.T",
    "9501.T", "9503.T", "1605.T", "5020.T",
    "9020.T", "9202.T", "2802.T"
]

plt.rcParams['font.family'] = 'sans-serif'

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾— & ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«è¨ˆç®—
# ==========================================
def download_data_safe(ticker, period="6mo", interval="1d", retries=3):
    wait = 2
    for _ in range(retries):
        try:
            df = yf.download(ticker, period=period, interval=interval, progress=False, auto_adjust=True)
            if df.empty: raise ValueError("Empty Data")
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.droplevel(1)
            return df
        except:
            time.sleep(wait); wait *= 2
    return None

def get_macro_data():
    """ä¸»è¦æŒ‡æ•°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—ã—ã¦æ•´å½¢"""
    tickers = {
        "^N225": "æ—¥çµŒå¹³å‡", "JPY=X": "ãƒ‰ãƒ«å††", "^GSPC": "ç±³S&P500", 
        "^TNX": "ç±³10å¹´å‚µåˆ©å›ã‚Š", "^VIX": "VIX(ææ€–æŒ‡æ•°)"
    }
    report = "ã€ğŸŒ ãƒã‚¯ãƒ­ç’°å¢ƒã€‘\n"
    try:
        data = yf.download(list(tickers.keys()), period="5d", progress=False)
        if isinstance(data.columns, pd.MultiIndex):
            df_close = data['Close']
        else:
            df_close = data['Close'] if 'Close' in data else data

        for symbol, name in tickers.items():
            try:
                series = df_close[symbol].dropna()
                if len(series) < 2: continue
                current = float(series.iloc[-1])
                prev = float(series.iloc[-2])
                change = (current - prev) / prev * 100
                icon = "â†—ï¸" if change > 0 else "â†˜ï¸"
                val_str = f"{current:.2f}"
                report += f"- {name}: {val_str} ({icon} {change:+.2f}%)\n"
            except: pass
    except:
        return "ã€ãƒã‚¯ãƒ­ç’°å¢ƒã€‘å–å¾—ã‚¨ãƒ©ãƒ¼"
    return report.strip()

def get_fundamentals(ticker):
    try:
        stock = yf.Ticker(ticker)
        try:
            info = stock.info
        except:
            return "ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘å–å¾—ä¸å¯"
            
        if not info: return "ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘ãƒ‡ãƒ¼ã‚¿ãªã—"

        name = info.get("longName", ticker)
        sector = info.get("sector", "-")
        per = info.get("trailingPE", "-")
        pbr = info.get("priceToBook", "-")
        roe = info.get("returnOnEquity", "-")
        
        per_str = f"{per:.1f}å€" if isinstance(per, (int, float)) else "-"
        pbr_str = f"{pbr:.2f}å€" if isinstance(pbr, (int, float)) else "-"
        roe_str = f"{roe*100:.1f}%" if isinstance(roe, (int, float)) else "-"

        return f"ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘\n- {name} ({sector})\n- PER: {per_str}, PBR: {pbr_str}, ROE: {roe_str}"
    except:
        return "ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘å–å¾—ã‚¨ãƒ©ãƒ¼"

def get_weekly_trend(ticker):
    """é€±è¶³ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š"""
    try:
        df = yf.download(ticker, period="2y", interval="1wk", progress=False, auto_adjust=True)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
        if len(df) < 26: return "ä¸æ˜"
        
        sma13 = df['Close'].rolling(13).mean().iloc[-1]
        sma26 = df['Close'].rolling(26).mean().iloc[-1]
        price = float(df['Close'].iloc[-1])
        
        if price > sma13 > sma26: return "ä¸Šæ˜‡ ğŸ“ˆ (å¼·)"
        elif price > sma13: return "ä¸Šæ˜‡ â†—ï¸ (çŸ­)"
        elif price < sma13 < sma26: return "ä¸‹é™ ğŸ“‰ (å¼±)"
        else: return "ãƒ¬ãƒ³ã‚¸ â¡ï¸"
    except: return "å–å¾—ã‚¨ãƒ©ãƒ¼"

def get_latest_news(ticker):
    # ç°¡æ˜“ç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾— (Google News RSS)
    try:
        q = urllib.parse.quote(f"{ticker} æ ªä¾¡ ãƒ‹ãƒ¥ãƒ¼ã‚¹")
        url = f"https://news.google.com/rss/search?q={q}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(url)
        if not feed.entries: return "ç‰¹ã«ãªã—"
        return "\n".join([f"ãƒ»{e.title}" for e in feed.entries[:2]])
    except: return "å–å¾—ã‚¨ãƒ©ãƒ¼"

def calculate_metrics_enhanced(df):
    if len(df) < 25: return None 
    curr = df.iloc[-1]
    price = float(curr['Close'])
    
    sma25 = float(curr['SMA25'])
    sma25_dev = ((price / sma25) - 1) * 100
    
    if len(df) < 6: return None
    prev_sma25 = float(df['SMA25'].iloc[-6]) 
    slope = (sma25 - prev_sma25) / 5
    trend_momentum = (slope / price) * 1000 
    
    macd = float(curr['MACD'])
    signal = float(curr['Signal'])
    macd_power = ((macd - signal) / price) * 10000 

    atr = float(curr['ATR'])
    entry_volatility = (atr / price) * 100

    # BBå¹…
    std = df['Close'].rolling(20).std().iloc[-1]
    bb_width = (4 * std) / df['Close'].rolling(20).mean().iloc[-1] * 100

    # å‡ºæ¥é«˜å€ç‡
    vol_ma5 = df['Volume'].rolling(5).mean().iloc[-1]
    volume_ratio = float(curr['Volume']) / vol_ma5 if vol_ma5 > 0 else 1.0

    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(9).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(9).mean()
    rs = gain / loss
    rsi_9 = 100 - (100 / (1 + rs)).iloc[-1]

    return {
        'sma25_dev': sma25_dev,
        'trend_momentum': trend_momentum,
        'macd_power': macd_power,
        'entry_volatility': entry_volatility,
        'price': price,
        'atr_value': atr,
        'bb_width': bb_width,
        'volume_ratio': volume_ratio,
        'rsi_9': rsi_9
    }

# ==========================================
# 2. CBRãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ 
# ==========================================
class CaseBasedMemory:
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.scaler = StandardScaler()
        self.knn = None
        self.df = pd.DataFrame()
        self.feature_cols = ['sma25_dev', 'trend_momentum', 'macd_power', 'entry_volatility']
        self.load_and_train()

    def load_and_train(self):
        if not os.path.exists(self.csv_path): return
        try:
            self.df = pd.read_csv(self.csv_path, on_bad_lines='skip')
            rename_map = {
                'date': 'Date', 'ticker': 'Ticker', 'action': 'Action', 
                'result': 'result', 'reason': 'Reason', 
                'confidence': 'Confidence',
                'stop_loss_price': 'stop_loss_price', 
                'stop_loss_reason': 'stop_loss_reason' 
            }
            self.df.columns = [rename_map.get(col.lower(), col) for col in self.df.columns]
            
            if len(self.df) < 5: return

            for col in self.feature_cols:
                if col not in self.df.columns: self.df[col] = 0.0

            features = self.df[self.feature_cols].fillna(0)
            self.features_normalized = self.scaler.fit_transform(features)
            
            self.knn = NearestNeighbors(n_neighbors=min(CBR_NEIGHBORS_COUNT, len(self.df)), metric='euclidean')
            self.knn.fit(self.features_normalized)
            print(f"Memory System: Loaded {len(self.df)} cases.")
        except Exception as e:
            print(f"Memory Load Error: {e}")

    def search_similar_cases(self, current_metrics):
        if self.knn is None or len(self.df) < 5:
            return "ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚å‚ç…§ãªã—ï¼‰"

        input_df = pd.DataFrame([current_metrics], columns=self.feature_cols)
        scaled_vec = self.scaler.transform(input_df) 
        distances, indices = self.knn.kneighbors(scaled_vec)
        
        text = f"ã€ã‚·ã‚¹ãƒ†ãƒ æ¤œç´¢: é¡ä¼¼éå»äº‹ä¾‹ã€‘\n"
        for idx in indices[0]:
            row = self.df.iloc[idx]
            res = str(row.get('result', ''))
            icon = "WIN â­•" if res=='WIN' else "LOSS âŒ" if res=='LOSS' else "â–"
            date = str(row.get('Date', ''))
            ticker = str(row.get('Ticker', ''))
            text += f"â— {date} {ticker} -> {icon}\n"
        return text

# ==========================================
# 3. AIåˆ†æ
# ==========================================
def create_chart_image(df, name):
    data = df.tail(100).copy()
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)
    ax1.plot(data.index, data['Close'], color='black', label='Close')
    ax1.plot(data.index, data['SMA25'], color='orange', label='SMA25')
    ax1.set_title(f"{name} Analysis")
    ax1.grid(True)
    ax2.plot(data.index, data['MACD'], color='red')
    ax2.bar(data.index, data['MACD']-data['Signal'], color='gray', alpha=0.3)
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=80); plt.close(fig); buf.seek(0)
    return {"mime_type": "image/png", "data": buf.getvalue()}

def analyze_vision_agent(model_instance, chart, metrics, cbr_text, macro, news, fundamentals, weekly_trend, name):
    """
    ã€AIåˆ¤æ–­ã€‘é«˜ç²¾åº¦ãƒ»ã‚¹ãƒŠã‚¤ãƒ‘ãƒ¼ç‰ˆ
    å …ç‰¢ã•ã‚’ç¶­æŒã—ã¤ã¤ã€ã€Œã‚¹ã‚¯ã‚¤ãƒ¼ã‚ºã€ã‚„ã€Œå‡ºæ¥é«˜ã€ã‚’è¦‹ã¦å‹ç‡ã®é«˜ã„å±€é¢ã‚’ç‹™ã†
    """
    
    trend_dir = "ä¸Šæ˜‡" if metrics['trend_momentum'] > 0 else "ä¸‹é™"

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è­¦å‘Š
    vol_msg = ""
    if metrics['entry_volatility'] >= 2.0:
        vol_msg = "âš ï¸ ç¾åœ¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒé«˜ã™ãã¾ã™(2.0%ä»¥ä¸Š)ã€‚æ–°è¦BUYã¯ç¦æ­¢ã€‚SELL(é€ƒã’)ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"

    prompt = f"""
ã‚ãªãŸã¯ã€Œç™¾ç™ºç™¾ä¸­ã®ã‚¹ãƒŠã‚¤ãƒ‘ãƒ¼ãƒ»ãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼ã€ã§ã™ã€‚
ã€Œè² ã‘ãªã„ã“ã¨ã€ã¯å½“ç„¶ã¨ã—ã¦ã€**ã€Œç¢ºå®Ÿã«å‹ã¦ã‚‹å±€é¢ã€ã ã‘** ã‚’é¸ã³æŠœã„ã¦ãã ã•ã„ã€‚

=== å…¥åŠ›æƒ…å ± ===
éŠ˜æŸ„: {name}
0. ãƒã‚¯ãƒ­ç’°å¢ƒï¼ˆå¸‚å ´å…¨ä½“ã®åœ°åˆã„ï¼‰:
   {macro}

1. ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ:
   - ãƒˆãƒ¬ãƒ³ãƒ‰: {trend_dir} (å‹¢ã„: {metrics['trend_momentum']:.2f})
   - SMA25ä¹–é›¢: {metrics['sma25_dev']:.2f}% (ãƒ—ãƒ©ã‚¹ãªã‚‰SMAã‚ˆã‚Šä¸Š)
   - ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {metrics['entry_volatility']:.2f}% (2.0%æœªæº€ãŒç†æƒ³)
    - **é€±è¶³(ä¸­æœŸ): {weekly_trend}  
   **ã€é‡è¦æŒ‡æ¨™ã€‘**
   - **BBå¹…(ã‚¹ã‚¯ã‚¤ãƒ¼ã‚ºåº¦)**: {metrics['bb_width']:.2f}% (10%æœªæº€ã¯ã‚¨ãƒãƒ«ã‚®ãƒ¼å……å¡«ä¸­)
   - **å‡ºæ¥é«˜å€ç‡**: {metrics['volume_ratio']:.2f}å€ (1.0è¶…ãˆã¯è³‡é‡‘æµå…¥)
   - **RSI(9)**: {metrics['rsi_9']:.1f} (40-60ã¯æŠ¼ã—ç›®è²·ã„ã®å¥½æ©Ÿ)

2. ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º:
   {fundamentals}

3. ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news}

{cbr_text}

=== åˆ¤æ–­åŸºæº– ===

{vol_msg}

**ã€BUY ğŸ”´: æ–°è¦è²·ã„ï¼ˆé«˜å‹ç‡ãƒãƒ£ãƒ³ã‚¹ï¼‰ã€‘**
ä»¥ä¸‹ã‚’ã™ã¹ã¦æº€ãŸã™ã€Œé»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚’å¿µé ­ã«ãŠã„ã¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã›ã‚ˆã€‚
1. **å®‰å…¨æ€§:** ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ 2.0% æœªæº€ã§ã‚ã‚‹ã“ã¨ã€‚
2. **ãƒˆãƒ¬ãƒ³ãƒ‰:** SMA25ãŒä¸Šå‘ãã§ã€ä¾¡æ ¼ãŒSMA25ã®ä¸Šã«ã‚ã‚‹ã“ã¨ã€‚
3. **ã‚¨ãƒƒã‚¸ (ä»¥ä¸‹ã®ã„ãšã‚Œã‹ãŒã‚ã‚‹ã“ã¨):**
   - **ã‚¹ã‚¯ã‚¤ãƒ¼ã‚ºã‹ã‚‰ã®åˆå‹•:** BBå¹…ãŒç‹­ãã€ã‹ã¤å‡ºæ¥é«˜ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚‹ã€‚
   - **æŠ¼ã—ç›®:** ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ã§ã€RSIãŒ 40ã€œ50 ã¾ã§èª¿æ•´ã—ã¦ã„ã‚‹ã€‚

**ã€HOLD ğŸŸ¡: æ§˜å­è¦‹ãƒ»ä¿æœ‰ç¶™ç¶šã€‘**
- ãƒˆãƒ¬ãƒ³ãƒ‰ã¯æ‚ªããªã„ãŒã€çˆ†ç™ºã®äºˆå…†ï¼ˆå‡ºæ¥é«˜æ€¥å¢—ãªã©ï¼‰ãŒãªã„å ´åˆã€‚
- è¿·ã†å ´åˆã¯ã™ã¹ã¦HOLDã‚’é¸æŠã›ã‚ˆã€‚

**ã€SELL ğŸ”µ: æ±ºæ¸ˆãƒ»é€ƒã’ï¼ˆæ‰‹ä»•èˆã„ã®åˆå›³ï¼‰ã€‘**
- ãƒˆãƒ¬ãƒ³ãƒ‰å´©å£Šã€ã¾ãŸã¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®æ€¥æ‹¡å¤§ã€‚
- â€»ç©ºå£²ã‚Šã§ã¯ãªãã€Œä¿æœ‰ãƒã‚¸ã‚·ãƒ§ãƒ³ã®æ±ºæ¸ˆï¼ˆé€ƒã’ï¼‰ã€ã®åˆå›³ã¨ã—ã¦åˆ¤æ–­ã™ã‚‹ã“ã¨ã€‚
- ãƒªã‚¹ã‚¯å›é¿ã‚’æœ€å„ªå…ˆã—ã€è² ã‘ãªã„ã“ã¨ã‚’æœ€é‡è¦è¦–ã›ã‚ˆã€‚

=== å‡ºåŠ› (JSONã®ã¿) ===
{{
  "action": "BUY", "HOLD", "SELL" ã®ã„ãšã‚Œã‹,
  "confidence": 0-100,
  "stop_loss_price": æ•°å€¤,
  "stop_loss_reason": "ç›´è¿‘å®‰å€¤ã‹ã¤ATR2å€ãƒ©ã‚¤ãƒ³... (30æ–‡å­—ä»¥å†…)",
  "reason": "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£1.2%ã¨ä½ãã€BBå¹…ãŒåç¸®ã—ãŸçŠ¶æ…‹ã§å‡ºæ¥é«˜ãŒ1.5å€ã«æ€¥å¢—ã€‚çˆ†ç™ºã®åˆå‹•ã¨åˆ¤æ–­... (100æ–‡å­—ä»¥å†…)"
}}
"""
    try:
        response = model_instance.generate_content([prompt, chart])
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        # â˜…ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«èµ¤å­—ã§è¡¨ç¤ºã™ã‚‹
        print(f"\nâš ï¸ AI ERROR: {e}") 
        return {"action": "HOLD", "confidence": 0, "reason": f"API Error: {e}", "stop_loss_price": 0}
    try:
        response = model_instance.generate_content([prompt, chart])
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        print(f"\nâš ï¸ AI ERROR: {e}") 
        return {"action": "HOLD", "confidence": 0, "reason": f"API Error: {e}", "stop_loss_price": 0}

def send_discord_notify(message):
    if not webhook_url: return
    try:
        chunk_size = 1900
        for i in range(0, len(message), chunk_size):
            chunk = message[i:i+chunk_size]
            requests.post(webhook_url, json={"content": chunk})
            time.sleep(1)
        print("âœ… Discordé€šçŸ¥é€ä¿¡")
    except Exception as e:
        print(f"âš ï¸ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

# ==========================================
# 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ (å®Ÿæˆ¦ç›£è¦–)
# ==========================================
# ==========================================
# 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ (å®Ÿæˆ¦ç›£è¦–)
# ==========================================
if __name__ == "__main__":
    today = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"=== AIå¸‚å ´ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  ({today}) ===")
    
    # ç›£è¦–ãƒªã‚¹ãƒˆã®é‡è¤‡æ’é™¤ã¨ã‚½ãƒ¼ãƒˆ
    WATCH_LIST = sorted(list(set(WATCH_LIST)))
    
    try:
        model_instance = genai.GenerativeModel(MODEL_NAME)
    except Exception as e:
        print(f"Error: {e}"); exit()

    cbr = CaseBasedMemory(LOG_FILE)
    macro = get_macro_data()
    print(macro)
    
    report_message = f"**ğŸ“Š AIå¸‚å ´ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ ({today})**\n\n{macro}\n"
    buy_list = []
    
    # ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å®šç¾©
    SAVE_TARGETS = [
        {"path": LOG_FILE, "name": "å­¦ç¿’ãƒ¡ãƒ¢ãƒª"},
        {"path": REAL_TRADE_LOG_FILE, "name": "å®Ÿæˆ¦ãƒ­ã‚°"}
    ]

    # â˜…è¿½åŠ : æ™‚é–“åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    # GitHub Actions(UTC)ã§ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«(JST)ã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«èª¿æ•´
    now_utc = datetime.datetime.utcnow()
    now_jst = now_utc + datetime.timedelta(hours=9)
    current_hour_jst = now_jst.hour
    
    # 15æ™‚ä»¥é™ãªã‚‰ä¿å­˜ãƒ¢ãƒ¼ãƒ‰ON
    is_closing_time = (current_hour_jst >= 15)
    
    if is_closing_time:
        print(f"ğŸ•’ ç¾åœ¨ {current_hour_jst}æ™‚: å¸‚å ´çµ‚äº†å¾Œã®ãŸã‚ã€Œè¨˜éŒ²ãƒ¢ãƒ¼ãƒ‰ã€ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
    else:
        print(f"ğŸ•’ ç¾åœ¨ {current_hour_jst}æ™‚: å¸‚å ´ç¨¼åƒä¸­ã®ãŸã‚ã€Œç›£è¦–ãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨˜éŒ²ãªã—ï¼‰ã€ã§å®Ÿè¡Œã—ã¾ã™ã€‚")

    for i, tic in enumerate(WATCH_LIST, 1):
        name = tic 
        print(f"[{i}/{len(WATCH_LIST)}] {name}... ", end="", flush=True)
        
        df = download_data_safe(tic, interval=TIMEFRAME)
        if df is None or len(df) < 100:
            print("Skip")
            continue
            
        df['SMA25'] = df['Close'].rolling(25).mean()
        df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()
        df['Signal'] = df['MACD'].ewm(span=9).mean()
        
        # ATRè¨ˆç®—ãªã©ï¼ˆçœç•¥ãªã—ã§ãã®ã¾ã¾ä½¿ã„ã¾ã™ï¼‰
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df['ATR'] = tr.rolling(14).mean()
        
        df = df.dropna()
        metrics = calculate_metrics_enhanced(df)
        if metrics is None: 
            print("Skip")
            continue
        
        cbr_text = cbr.search_similar_cases(metrics)
        chart = create_chart_image(df, name)
        news = get_latest_news(name)
        fundamentals = get_fundamentals(name)
        weekly_trend = get_weekly_trend(name)
        
        # AIåˆ†æå®Ÿè¡Œ
        res = analyze_vision_agent(model_instance, chart, metrics, cbr_text, macro, news, fundamentals, weekly_trend, name)
              
        action = res.get('action', 'HOLD')
        conf = res.get('confidence', 0)
        sl_price_raw = res.get('stop_loss_price', 0)
        try: sl_price = float(sl_price_raw)
        except: sl_price = 0.0
        
        # --- ä¿å­˜ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ ---
        item = {
            "Date": today, "Ticker": tic, "Timeframe": TIMEFRAME, 
            "Action": action, "result": "", 
            "Reason": res.get('reason', 'None'), 
            "Confidence": conf,
            "stop_loss_price": sl_price, 
            "stop_loss_reason": res.get('stop_loss_reason', '-'),
            "Price": metrics['price'],
            "sma25_dev": metrics['sma25_dev'], 
            "trend_momentum": metrics['trend_momentum'],
            "macd_power": metrics['macd_power'],
            "entry_volatility": metrics['entry_volatility'],
            "profit_loss": 0
        }
        
        csv_columns = [
            "Date", "Ticker", "Timeframe", "Action", "result", "Reason", 
            "Confidence", "stop_loss_price", "stop_loss_reason", "Price", 
            "sma25_dev", "trend_momentum", "macd_power", "entry_volatility", "profit_loss"
        ]
        
        df_new = pd.DataFrame([item])
        for col in csv_columns:
            if col not in df_new.columns: df_new[col] = None
        df_new = df_new[csv_columns]

        # --- â˜…æ¡ä»¶ä»˜ãä¿å­˜å‡¦ç† (æ™‚é–“åˆ¶é™ + é‡è¤‡ãƒã‚§ãƒƒã‚¯) ---
        if is_closing_time:
            for target in SAVE_TARGETS:
                path = target["path"]
                name_label = target["name"]
                
                try:
                    if os.path.exists(path):
                        try:
                            df_exist = pd.read_csv(path, on_bad_lines='skip')
                            is_duplicate = ((df_exist['Date'] == today) & (df_exist['Ticker'] == tic)).any()
                            
                            if is_duplicate:
                                pass # æ—¢ã«ä¿å­˜æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
                            else:
                                df_new.to_csv(path, mode='a', header=False, index=False, encoding='utf-8-sig')
                                print(f"ğŸ“ {name_label}ä¿å­˜", end=" ")
                        except:
                            df_new.to_csv(path, mode='a', header=False, index=False, encoding='utf-8-sig')
                    else:
                        df_new.to_csv(path, index=False, encoding='utf-8-sig')
                        print(f"ğŸ†• {name_label}ä½œæˆ", end=" ")
                        
                except Exception as e:
                    print(f"âŒä¿å­˜ã‚¨ãƒ©ãƒ¼:{e}", end=" ")
        else:
            # 15æ™‚å‰ã¯ä½•ã‚‚ã—ãªã„ï¼ˆé€šçŸ¥ã®ã¿ï¼‰
            pass

        # --- ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º ---
        action_icon = "ğŸ”´" if action == "BUY" else "ğŸ”µ" if action == "SELL" else "ğŸŸ¡"
        sl_str = f"(SL: {sl_price:.0f})" if action == "BUY" and sl_price > 0 else ""
        print(f"-> {action_icon} {conf}% {sl_str}")

        if action == "BUY":
            sl_str = f"(SL: {sl_price:.0f}å††)" if sl_price > 0 else ""
            msg = f"ğŸ”´ **BUY {name}**: {metrics['price']:.0f}å†† {sl_str}\n> ç†ç”±: {res.get('reason')}"
            buy_list.append(msg)
            
        elif action == "SELL":
            msg = f"ğŸ”µ **SELL (æ±ºæ¸ˆ) {name}**: {metrics['price']:.0f}å††\n> ç†ç”±: {res.get('reason')}"
            buy_list.append(msg)
            
        time.sleep(2)

    # é€šçŸ¥ä½œæˆ
    if buy_list:
        report_message += "\nğŸš€ **æ–°è¦BUY/SELLéŠ˜æŸ„**\n" + "\n\n".join(buy_list)
    else:
        report_message += "\nğŸ’¤ æœ¬æ—¥ã¯ã€ŒBUY/SELLã€éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    if not is_closing_time:
        report_message += "\n(â€»å¸‚å ´ç¨¼åƒä¸­ã®ãŸã‚ã€è¨˜éŒ²ã¯è¡Œã£ã¦ã„ã¾ã›ã‚“)"

    # Discordé€ä¿¡
    send_discord_notify(report_message)

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    try:
        report_dir = "reports"
        os.makedirs(report_dir, exist_ok=True)
        file_path = os.path.join(report_dir, "latest_report.txt")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(report_message)
    except: pass