import yfinance as yf
import pandas as pd
import google.generativeai as genai
import json
import time
import datetime
import urllib.parse
import feedparser
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import os
import io
import sys 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import socket
import requests.packages.urllib3.util.connection as urllib3_cn
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import logging

# ---------------------------------------------------------
# â˜…ç’°å¢ƒè¨­å®š
# ---------------------------------------------------------
sys.stdout.reconfigure(encoding='utf-8')

def allowed_gai_family():
    return socket.AF_INET
urllib3_cn.allowed_gai_family = allowed_gai_family

try:
    from dotenv import load_dotenv
    load_dotenv(override=True)
except ImportError:
    pass

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

webhook_url = os.getenv("DISCORD_WEBHOOK_URL")

# â˜…ä¿®æ­£: transport='rest' ã‚’æŒ‡å®šã—ã¦ãƒ•ãƒªãƒ¼ã‚ºã‚’å›é¿
genai.configure(api_key=GOOGLE_API_KEY, transport="rest")

# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
LOG_FILE = "ai_trade_memory_risk_managed.csv" 
REAL_TRADE_LOG_FILE = "real_trade_record.csv" 
MODEL_NAME = 'models/gemini-3.0-pro-preview' # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«

TIMEFRAME = "1d"
CBR_NEIGHBORS_COUNT = 15

# ç›£è¦–ãƒªã‚¹ãƒˆ
WATCH_LIST = [
    "6146.T", "8035.T", "9983.T", "7741.T", "6857.T", "7012.T", "6367.T", "7832.T",
    "1801.T", "9766.T", "2801.T", "4063.T", "4543.T", "4911.T", "4507.T",
    "9432.T", "9433.T", "9434.T", "4503.T", "4502.T", "2502.T", "2503.T", "2802.T",
    "4901.T", "1925.T", "1928.T", "1802.T", "1803.T", "1812.T", "9020.T", "9021.T",
    "9532.T", "9735.T", "9613.T",
    "8306.T", "8316.T", "8411.T", "8308.T", "8309.T", "8331.T", "8354.T", "8766.T",
    "8725.T", "8591.T", "8593.T", "8604.T", "8473.T", "8630.T", "8697.T",
    "8058.T", "8031.T", "8001.T", "8002.T", "8015.T", "2768.T", "8053.T", "7459.T",
    "8088.T", "9962.T", "3092.T", "3382.T",
    "7011.T", "7013.T", "6301.T", "7203.T", "7267.T", "7269.T", "7270.T", "7201.T",
    "5401.T", "5411.T", "5713.T", "1605.T", "5020.T",
    "6501.T", "6503.T", "6305.T", "6326.T", "6383.T", "6471.T", "6473.T", "7751.T"
]

plt.rcParams['font.family'] = 'sans-serif'

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ç¾¤
# ==========================================
def download_data_safe(ticker, period="6mo", interval="1d", retries=3):
    wait = 2
    for attempt in range(retries):
        try:
            logging.getLogger('yfinance').setLevel(logging.CRITICAL)
            df = yf.download(ticker, period=period, interval=interval, progress=False, auto_adjust=True)
            if df.empty: return None
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
            if len(df) < 50: return None
            return df
        except:
            time.sleep(wait); wait *= 2
    return None

def get_macro_data():
    tickers = {"^N225": "æ—¥çµŒå¹³å‡", "JPY=X": "ãƒ‰ãƒ«å††", "^GSPC": "ç±³S&P500"}
    report = "ã€ğŸŒ ãƒã‚¯ãƒ­ç’°å¢ƒã€‘\n"
    try:
        data = yf.download(list(tickers.keys()), period="5d", progress=False)
        if isinstance(data.columns, pd.MultiIndex): df_close = data['Close']
        else: df_close = data['Close'] if 'Close' in data else data

        for symbol, name in tickers.items():
            try:
                series = df_close[symbol].dropna()
                if len(series) < 2: continue
                current = float(series.iloc[-1])
                change = (current - float(series.iloc[-2])) / float(series.iloc[-2]) * 100
                icon = "â†—ï¸" if change > 0 else "â†˜ï¸"
                report += f"- {name}: {current:.2f} ({icon} {change:+.2f}%)\n"
            except: pass
    except: return "ã€ãƒã‚¯ãƒ­ç’°å¢ƒã€‘å–å¾—ã‚¨ãƒ©ãƒ¼"
    return report.strip()

def get_fundamentals(ticker):
    try:
        info = yf.Ticker(ticker).info
        return f"PER:{info.get('trailingPE','-')} PBR:{info.get('priceToBook','-')} ROE:{info.get('returnOnEquity','-')}"
    except: return "ãƒ‡ãƒ¼ã‚¿ãªã—"

def get_latest_news(ticker):
    try:
        q = urllib.parse.quote(f"{ticker} æ ªä¾¡ ãƒ‹ãƒ¥ãƒ¼ã‚¹")
        url = f"https://news.google.com/rss/search?q={q}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(url)
        return feed.entries[0].title if feed.entries else "ç‰¹ã«ãªã—"
    except: return "å–å¾—ã‚¨ãƒ©ãƒ¼"

def get_earnings_date(ticker):
    try:
        cal = yf.Ticker(ticker).calendar
        if cal and 'Earnings Date' in cal:
            return cal['Earnings Date'][0].strftime('%Y-%m-%d')
    except: pass
    return "-"

def get_weekly_trend(ticker):
    try:
        df = yf.download(ticker, period="1y", interval="1wk", progress=False, auto_adjust=True)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(1)
        if len(df) < 26: return "ä¸æ˜"
        price = float(df['Close'].iloc[-1])
        sma13 = df['Close'].rolling(13).mean().iloc[-1]
        sma26 = df['Close'].rolling(26).mean().iloc[-1]
        if price > sma13 > sma26: return "ä¸Šæ˜‡ ğŸ“ˆ"
        elif price > sma13: return "ä¸Šæ˜‡ â†—ï¸"
        elif price < sma13 < sma26: return "ä¸‹é™ ğŸ“‰"
        else: return "ãƒ¬ãƒ³ã‚¸ â¡ï¸"
    except: return "ä¸æ˜"

# ==========================================
# 2. æŒ‡æ¨™è¨ˆç®— & é‰„ã®æŸ
# ==========================================
def calculate_metrics_enhanced(df):
    if len(df) < 26: return None
    curr = df.iloc[-1]
    price = float(curr['Close'])
    
    sma25 = float(curr['SMA25'])
    sma25_dev = ((price / sma25) - 1) * 100
    
    prev_sma25 = float(df['SMA25'].iloc[-6])
    slope = (sma25 - prev_sma25) / 5
    trend_momentum = (slope / price) * 1000
    
    macd = float(curr['MACD'])
    signal = float(curr['Signal'])
    macd_power = ((macd - signal) / price) * 10000
    
    atr = float(curr['ATR'])
    entry_volatility = (atr / price) * 100
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(9).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(9).mean()
    rs = gain / loss
    rsi_9 = 100 - (100 / (1 + rs)).iloc[-1]

    return {
        'sma25_dev': sma25_dev,
        'trend_momentum': trend_momentum,
        'macd_power': macd_power,
        'entry_volatility': entry_volatility,
        'price': price,
        'atr_value': atr,
        'rsi_9': rsi_9
    }

def check_iron_rules(metrics):
    """APIå‘¼ã³å‡ºã—å‰ã®é–€å‰æ‰•ã„ãƒã‚§ãƒƒã‚¯"""
    if metrics['entry_volatility'] > 2.3:
        return {"action": "HOLD", "reason": f"ã€é‰„ã®æŸã€‘ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£éå¤§ ({metrics['entry_volatility']:.2f}%)"}
    if metrics['entry_volatility'] < 1.5:
        return {"action": "HOLD", "reason": f"ã€é‰„ã®æŸã€‘ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£éå° ({metrics['entry_volatility']:.2f}%)"}
    if metrics['trend_momentum'] < 0:
        return {"action": "HOLD", "reason": "ã€é‰„ã®æŸã€‘ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ (Momentum < 0)"}
    if metrics['sma25_dev'] < 0:
        return {"action": "HOLD", "reason": "ã€é‰„ã®æŸã€‘SMA25å‰²ã‚Œ (æˆ»ã‚Šå¾…ã¡)"}
    return None

# ==========================================
# 3. CBRãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ 
# ==========================================
class CaseBasedMemory:
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.scaler = StandardScaler()
        self.knn = None
        self.df = pd.DataFrame()
        self.feature_cols = ['sma25_dev', 'trend_momentum', 'macd_power', 'entry_volatility', 'rsi_9']
        self.csv_columns = [
            "Date", "Ticker", "Timeframe", "Action", "result", "Reason", 
            "Confidence", "stop_loss_price", "stop_loss_reason", "Price", 
            "sma25_dev", "trend_momentum", "macd_power", "entry_volatility", 
            "rsi_9", "profit_loss", "profit_rate" 
        ]
        self.load_and_train()

    def load_and_train(self):
        if not os.path.exists(self.csv_path): return
        try:
            self.df = pd.read_csv(self.csv_path)
            for col in self.csv_columns:
                if col not in self.df.columns: self.df[col] = 0.0
        except Exception:
            try:
                self.df = pd.read_csv(self.csv_path, on_bad_lines='skip')
                for col in self.csv_columns: self.df[col] = 0.0
            except: return

        try:
            self.df.columns = [c.strip() for c in self.df.columns]
            rename_map = {'ticker': 'Ticker', 'result': 'result'}
            self.df.rename(columns=rename_map, inplace=True)
            
            valid_df = self.df[self.df['result'].isin(['WIN', 'LOSS'])].copy()
            if len(valid_df) > 5:
                features = valid_df[self.feature_cols].fillna(0)
                self.features_normalized = self.scaler.fit_transform(features)
                self.valid_df_for_knn = valid_df 
                global CBR_NEIGHBORS_COUNT
                self.knn = NearestNeighbors(n_neighbors=min(CBR_NEIGHBORS_COUNT, len(valid_df)), metric='euclidean')
                self.knn.fit(self.features_normalized)
        except Exception as e:
            print(f"Memory Init Error: {e}")

    def search_similar_cases(self, current_metrics):
        if self.knn is None: return "ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"
        vec = [current_metrics.get(col, 0) for col in self.feature_cols]
        input_df = pd.DataFrame([vec], columns=self.feature_cols)
        dists, indices = self.knn.kneighbors(self.scaler.transform(input_df))
        
        text = f"ã€é¡ä¼¼éå»äº‹ä¾‹ã€‘\n"
        win_c = 0; loss_c = 0
        for idx in indices[0]:
            row = self.valid_df_for_knn.iloc[idx]
            res = str(row.get('result', ''))
            if res == 'WIN': win_c += 1
            if res == 'LOSS': loss_c += 1
            icon = "â­•" if res=='WIN' else "âŒ"
            text += f"- {row.get('Date')} {row.get('Ticker')}: {icon}\n"
        text += f"-> å‚¾å‘: å‹ã¡{win_c} / è² ã‘{loss_c}\n"
        return text

# ==========================================
# 4. AIåˆ¤å®š
# ==========================================
def create_chart_image(df, name):
    data = df.tail(100).copy()
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)
    ax1.plot(data.index, data['Close'], color='black', label='Close')
    ax1.plot(data.index, data['SMA25'], color='orange', label='SMA25')
    ax1.set_title(f"{name} Analysis")
    ax1.legend(); ax1.grid(True, alpha=0.3)
    ax2.plot(data.index, data['MACD'], color='red')
    ax2.bar(data.index, data['MACD']-data['Signal'], color='gray', alpha=0.3)
    ax2.grid(True, alpha=0.3)
    buf = io.BytesIO(); plt.savefig(buf, format='png', dpi=80); plt.close(fig); buf.seek(0)
    return {"mime_type": "image/png", "data": buf.getvalue()}

def ai_decision_maker(model, chart_bytes, metrics, cbr_text, macro, news, fundamentals, weekly, ticker):
    # â˜…APIå‘¼ã³å‡ºã—
    prompt = f"""
### CONTEXT
å¯¾è±¡: {ticker}
æŒ‡æ¨™: Momentum {metrics['trend_momentum']:.2f}, SMAä¹–é›¢ {metrics['sma25_dev']:.2f}%, Vol {metrics['entry_volatility']:.2f}%, RSI {metrics['rsi_9']:.1f}
é€±è¶³: {weekly}
{macro}
{fundamentals}
{news}
{cbr_text}

### TASK
ã€Œè³‡ç”£é˜²è¡›å‹AIã€ã¨ã—ã¦ã€Œè²·ã„ (BUY)ã€ã‹ã€Œæ§˜å­è¦‹ (HOLD)ã€ã®ã¿åˆ¤å®šã›ã‚ˆã€‚ç©ºå£²ã‚Šä¸å¯ã€‚
å£²å´åˆ¤æ–­ã¯ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã«ä¸€ä»»ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã€Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®å„ªä½æ€§ã€ã®ã¿ã‚’å¯©æŸ»ã™ã‚‹ã€‚

### RULES (çµ±è¨ˆçš„å„ªä½æ€§ã«åŸºã¥ãé‰„ã®æŸ)

**1. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ç¦æ­¢ (å³æ™‚HOLDå¯¾è±¡):**
   ä»¥ä¸‹ã®ã„ãšã‚Œã‹1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã¯ã€çµ¶å¯¾ã«BUYã—ã¦ã¯ãªã‚‰ãªã„ã€‚
   - **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ >= 2.6%**: (å‹ç‡34%ä»¥ä¸‹) ç›¸å ´ãŒè’ã‚Œã¦ãŠã‚Šå±é™ºã€‚
   - **SMA25ä¹–é›¢ç‡ <= 0.5%**: (å‹ç‡32%ä»¥ä¸‹) ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå‡ºã¦ã„ãªã„ã€ã¾ãŸã¯é€†å¼µã‚Šã€‚SMA25ã¯å››æ¨äº”å…¥ã§ã¯ãªã
   - **MACDãƒ‘ãƒ¯ãƒ¼ <= 0**: (å‹ç‡ä½) ä¸‹è½åœ§åŠ›ãŒæ®‹ã£ã¦ã„ã‚‹ã€‚

**2. BUY (æ–°è¦è²·ã„) ã®æ¡ä»¶:**
   *å‰æ: ä¸Šè¨˜ã®ç¦æ­¢æ¡ä»¶ã‚’å…¨ã¦ã‚¯ãƒªã‚¢ã—ã¦ã„ã‚‹ã“ã¨ã€‚*
   
   - **[ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³]:**
     - SMA25ä¹–é›¢ç‡ãŒ **+0.5% ã€œ +4.7%** ã®ç¯„å›²ã«ã‚ã‚‹ã€‚
     - MACDãƒ‘ãƒ¯ãƒ¼ãŒãƒ—ãƒ©ã‚¹ã§æ¨ç§»ã—ã¦ã„ã‚‹ã€‚
     - RSIãŒ 40ã€œ65 ã®ç¯„å›²ï¼ˆéç†±æ„ŸãŒãªã„ï¼‰ã€‚

### SCORING (è‡ªä¿¡åº¦ã®æ¡ç‚¹ - å³æ ¼åŒ–)**
   ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœã€**è‡ªä¿¡éå‰°(85ç‚¹ä»¥ä¸Š)ã¯è² ã‘ãƒ•ãƒ©ã‚°**ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹ã€‚
   - **80-85 (æ¨å¥¨):** [ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¾ãƒ¼ãƒ³] ã«å®Œå…¨ã«åˆè‡´ã—ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%æœªæº€ã®å ´åˆã€‚
   - **60-79 (æ…é‡):** æ¡ä»¶ã¯æº€ãŸã™ãŒã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ2.0%ã€œ2.6%ã®å ´åˆã€‚
   - **0 (è«–å¤–):** ç¦æ­¢æ¡ä»¶ã«1ã¤ã§ã‚‚è©²å½“ã™ã‚‹å ´åˆã€‚è‡ªä¿¡åº¦ã‚’0ã«ã›ã‚ˆã€‚

### OUTPUT FORMAT (JSON ONLY)
{{
  "action": "BUY", "HOLD", "SELL",
  "confidence": 0-100,
  "stop_loss_price": 0.0,
  "stop_loss_reason": "ç†ç”±",
  "target_price": 0.0,
  "reason": "ç†ç”±(100æ–‡å­—ä»¥å†…)"
}}
"""
    safety = {HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE}
    try:
        response = model.generate_content([prompt, chart_bytes], safety_settings=safety)
        text = response.text.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match: text = match.group(0)
        return json.loads(text)
    except Exception as e:
        return {"action": "HOLD", "reason": f"AI Error: {e}", "confidence": 0}

def send_discord_notify(message, filename=None):
    if not webhook_url: return
    try:
        now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
        payload = {"content": f"ğŸ“Š **AIå¸‚å ´ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ ({now_str})**\n{message[:1500]}"}
        files = {}
        if filename:
            files["file"] = (f"Report_{now_str.replace(':','-')}.txt", message.encode('utf-8'))
        requests.post(webhook_url, data=payload, files=files if filename else None)
        print("âœ… Discordé€šçŸ¥é€ä¿¡")
    except Exception as e:
        print(f"âš ï¸ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

# ==========================================
# 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==========================================
if __name__ == "__main__":
    today = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"=== AIå¸‚å ´ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  ({today}) ===")
    
    WATCH_LIST = sorted(list(set(WATCH_LIST)))
    try: model_instance = genai.GenerativeModel(MODEL_NAME)
    except Exception as e: print(f"Error: {e}"); exit()

    memory = CaseBasedMemory(LOG_FILE)
    macro = get_macro_data()
    print(macro)
    
    report_message = f"**ğŸ“Š AIå¸‚å ´ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ ({today})**\n\n{macro}\n"
    buy_list = []
    all_stock_prices = [] 
    
    SAVE_TARGETS = [
        {"path": LOG_FILE, "name": "å­¦ç¿’ãƒ¡ãƒ¢ãƒª"},
        {"path": REAL_TRADE_LOG_FILE, "name": "å®Ÿæˆ¦ãƒ­ã‚°"}
    ]

    current_hour_jst = (datetime.datetime.utcnow() + datetime.timedelta(hours=9)).hour
    is_closing_time = (current_hour_jst >= 15)
    print(f"ğŸ•’ ç¾åœ¨ {current_hour_jst}æ™‚: {'è¨˜éŒ²ãƒ¢ãƒ¼ãƒ‰' if is_closing_time else 'ç›£è¦–ãƒ¢ãƒ¼ãƒ‰'}")

    for i, tic in enumerate(WATCH_LIST, 1):
        print(f"[{i}/{len(WATCH_LIST)}] {tic}... ", end="", flush=True)
        
        df = download_data_safe(tic)
        if df is None: print("Skip"); continue
        
        df['SMA25'] = df['Close'].rolling(25).mean()
        df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()
        df['Signal'] = df['MACD'].ewm(span=9).mean()
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        df['ATR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1).rolling(14).mean()
        
        df = df.dropna()
        metrics = calculate_metrics_enhanced(df)
        if metrics is None: print("Skip"); continue
        
        # --- æ ªä¾¡ãƒªã‚¹ãƒˆç”¨ ---
        current_price = metrics['price']
        try:
            prev_close = df['Close'].iloc[-2]
            change = current_price - prev_close
            change_pct = (change / prev_close) * 100
            price_str = f"â€¢ {tic}: {current_price:,.0f}å†† ({change:+.0f} / {change_pct:+.2f}%)"
        except: price_str = f"â€¢ {tic}: {current_price:,.0f}å††"
        all_stock_prices.append(price_str)

        # â˜…é‰„ã®æŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (AIå‘¼ã³å‡ºã—å‰ã«å®Ÿè¡Œ)
        iron_res = check_iron_rules(metrics)
        if iron_res:
            print("â¹ï¸ Filtered")
            continue

        earnings_date = get_earnings_date(tic)
        cbr_text = memory.search_similar_cases(metrics)
        chart = create_chart_image(df, tic)
        news = get_latest_news(tic)
        fund = get_fundamentals(tic)
        weekly = get_weekly_trend(tic)
        
        res = ai_decision_maker(model_instance, chart, metrics, cbr_text, macro, news, fund, weekly, tic)
        
        action = res.get('action', 'HOLD')
        conf = res.get('confidence', 0)
        
        # ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°è¨ˆç®—
        stop_loss_price = 0
        if action == "BUY":
            atr_stop = metrics['atr_value'] * 1.5 # æåˆ‡ã‚Šæµ…ã‚
            stop_loss_price = metrics['price'] - atr_stop
        
        # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ
        item = {
            "Date": today, "Ticker": tic, "Timeframe": TIMEFRAME, 
            "Action": action, "result": "", "Reason": res.get('reason', 'None'), 
            "Confidence": conf, "stop_loss_price": stop_loss_price, "stop_loss_reason": "ATR_Trailing_Stop",
            "Price": metrics['price'], "sma25_dev": metrics['sma25_dev'], 
            "trend_momentum": metrics['trend_momentum'], "macd_power": metrics['macd_power'],
            "entry_volatility": metrics['entry_volatility'], 
            "rsi_9": metrics['rsi_9'], 
            "profit_loss": 0, "profit_rate": 0.0 
        }
        
        if is_closing_time:
            df_new = pd.DataFrame([item])
            for col in memory.csv_columns:
                if col not in df_new.columns: df_new[col] = None
            df_new = df_new[memory.csv_columns]
            
            for target in SAVE_TARGETS:
                try:
                    path = target["path"]
                    if os.path.exists(path):
                        df_new.to_csv(path, mode='a', header=False, index=False, encoding='utf-8-sig')
                    else:
                        df_new.to_csv(path, index=False, encoding='utf-8-sig')
                except: pass
            print(f"ğŸ“ {action} ({conf}%)")
        else:
            print(f"ğŸ‘€ {action} ({conf}%)")

        if action == "BUY" and conf >= 70:
            earnings_warning = f"\nâš ï¸ **æ±ºç®—æ³¨æ„**: {earnings_date}" if earnings_date != "-" else ""
            msg = (
                f"ğŸ”´ **BUY {tic}**: {metrics['price']:.0f}å††\n"
                f"ğŸ›¡ï¸ **æ¨å¥¨æåˆ‡ã‚Š**: **{stop_loss_price:.0f}å††** (ATR x1.5)\n"
                f"ğŸ’¡ **é‹ç”¨ãƒ¡ãƒ¢**: \n"
                f"ãƒ»åˆæœŸæåˆ‡ã‚Šã¯æµ…ãè¨­å®š\n"
                f"ãƒ»å«ã¿ç›Š+5%ã¾ã§ã¯æˆ‘æ…¢ã—ã¦ä¼¸ã°ã™\n"
                f"{earnings_warning}\n"
                f"> ç†ç”±: {res.get('reason')}"
            )
            buy_list.append(msg)
        time.sleep(2)

    if buy_list:
        report_message += "\n\nğŸš€ **æ–°è¦BUYæ¨å¥¨**\n" + "\n\n".join(buy_list)
    else:
        report_message += "\n\nğŸ’¤ æ¨å¥¨ãªã—"

    if all_stock_prices:
        report_message += "\n\n" + "="*30 + "\nğŸ“‰ **ç›£è¦–éŠ˜æŸ„ æ ªä¾¡ä¸€è¦§**\n" + "="*30 + "\n"
        report_message += "\n".join(all_stock_prices)

    send_discord_notify(report_message, filename="FullReport")